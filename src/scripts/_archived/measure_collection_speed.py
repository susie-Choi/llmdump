#!/usr/bin/env python3
"""
Measure actual data collection speed and identify bottlenecks.

This script:
1. Collects a small sample of data
2. Measures actual collection speed
3. Estimates time for full collection
4. Identifies bottlenecks (API keys, rate limits, etc.)
"""

import sys
import time
import os
import requests
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta

# Load .env file if exists
try:
    from dotenv import load_dotenv
    env_path = Path('.env')
    if env_path.exists():
        load_dotenv(env_path)
        print(f"[INFO] Loaded .env file from {env_path.absolute()}")
except ImportError:
    pass  # python-dotenv not installed, skip
except Exception as e:
    print(f"[WARN] Failed to load .env file: {e}")

sys.path.insert(0, str(Path(__file__).parent.parent))

from llmdump.spokes.cve import CVECollector
from llmdump.spokes.github import GitHubSignalsCollector
from llmdump.spokes.epss import EPSSCollector


def measure_cve_collection_speed(num_samples: int = 10) -> Dict[str, Any]:
    """Measure CVE collection speed."""
    print(f"\n[MEASURE] Measuring CVE collection speed ({num_samples} samples)...")
    
    api_key = os.getenv("NVD_API_KEY")
    has_key = api_key is not None
    
    collector = CVECollector(api_key=api_key)
    
    # Test CVEs
    test_cves = [
        'CVE-2021-44228', 'CVE-2021-45046', 'CVE-2021-45105',
        'CVE-2021-3156', 'CVE-2021-26855', 'CVE-2020-0601',
        'CVE-2017-5638', 'CVE-2014-0160', 'CVE-2017-0144',
        'CVE-2014-6271',
    ][:num_samples]
    
    times = []
    errors = []
    
    start_total = time.time()
    
    for i, cve_id in enumerate(test_cves, 1):
        print(f"  [{i}/{num_samples}] Collecting {cve_id}...", end=' ', flush=True)
        
        start = time.time()
        try:
            result = collector._collect_by_id(cve_id)
            elapsed = time.time() - start
            times.append(elapsed)
            print(f"[OK] {elapsed:.2f}ì´ˆ")
        except Exception as e:
            elapsed = time.time() - start
            errors.append({'cve_id': cve_id, 'error': str(e), 'time': elapsed})
            print(f"[ERROR] {elapsed:.2f}ì´ˆ - {str(e)[:50]}")
    
    total_time = time.time() - start_total
    
    if not times:
        return {
            'success': False,
            'error': 'All samples failed',
            'errors': errors,
        }
    
    avg_time = sum(times) / len(times)
    min_time = min(times)
    max_time = max(times)
    
    # Calculate rate limit
    rate_limit_seconds = 0.6 if has_key else 6.0
    effective_rate = 1.0 / max(avg_time, rate_limit_seconds)
    
    recommendation = _get_cve_recommendation(has_key, avg_time, rate_limit_seconds)
    
    return {
        'success': True,
        'authenticated': has_key,
        'samples': len(times),
        'errors': len(errors),
        'times': {
            'total': total_time,
            'average': avg_time,
            'min': min_time,
            'max': max_time,
        },
        'rate_limit_seconds': rate_limit_seconds,
        'effective_rate_per_hour': effective_rate * 3600,
        'bottleneck': 'rate_limit' if avg_time < rate_limit_seconds else 'network',
        'recommendation': recommendation.get('summary', ''),
        'recommendation_details': recommendation,
    }


def measure_github_collection_speed(repo: str = 'torvalds/linux', days_back: int = 7) -> Dict[str, Any]:
    """Measure GitHub commit collection speed."""
    print(f"\n[MEASURE] Measuring GitHub commit collection speed...")
    print(f"  Repository: {repo}")
    print(f"  Days back: {days_back}")
    
    token = os.getenv("GITHUB_TOKEN")
    if not token:
        return {
            'success': False,
            'error': 'GITHUB_TOKEN not set',
            'recommendation': 'GitHub tokenì´ ì—†ìŠµë‹ˆë‹¤. 60/hour ì œí•œì´ ì ìš©ë©ë‹ˆë‹¤.',
        }
    
    try:
        collector = GitHubSignalsCollector(token=token)
        
        # Check rate limit first
        print("  Checking rate limit...", end=' ', flush=True)
        rate_limit_url = "https://api.github.com/rate_limit"
        rate_response = requests.get(rate_limit_url, headers=collector.headers, timeout=10)
        
        if rate_response.status_code == 200:
            rate_data = rate_response.json()['resources']['core']
            remaining = rate_data['remaining']
            limit = rate_data['limit']
            print(f"[OK] {remaining}/{limit} ë‚¨ìŒ")
        else:
            print(f"[WARN] Rate limit í™•ì¸ ì‹¤íŒ¨")
            remaining = None
            limit = None
        
        # Measure commit collection
        print("  Collecting commits...", end=' ', flush=True)
        since = datetime.now() - timedelta(days=days_back)
        
        start = time.time()
        commits = collector._collect_commits(repo, since)
        elapsed = time.time() - start
        
        num_commits = len(commits)
        commits_per_second = num_commits / elapsed if elapsed > 0 else 0
        
        print(f"[OK] {num_commits}ê°œ ìˆ˜ì§‘ ({elapsed:.2f}ì´ˆ)")
        
        # Estimate for larger collection
        estimated_rate = commits_per_second * 3600  # per hour
        
        recommendation = _get_github_recommendation(remaining, limit, estimated_rate)
        
        return {
            'success': True,
            'authenticated': limit != 60,
            'commits_collected': num_commits,
            'time_seconds': elapsed,
            'commits_per_second': commits_per_second,
            'commits_per_hour': estimated_rate,
            'rate_limit': {
                'remaining': remaining,
                'limit': limit,
            },
            'recommendation': recommendation.get('summary', ''),
            'recommendation_details': recommendation,
        }
        
    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'recommendation': f'GitHub API ì˜¤ë¥˜: {e}',
        }


def measure_epss_collection_speed(num_samples: int = 10) -> Dict[str, Any]:
    """Measure EPSS collection speed."""
    print(f"\n[MEASURE] Measuring EPSS collection speed ({num_samples} samples)...")
    
    collector = EPSSCollector()
    
    test_cves = [
        'CVE-2021-44228', 'CVE-2021-45046', 'CVE-2021-45105',
        'CVE-2021-3156', 'CVE-2021-26855', 'CVE-2020-0601',
        'CVE-2017-5638', 'CVE-2014-0160', 'CVE-2017-0144',
        'CVE-2014-6271',
    ][:num_samples]
    
    start = time.time()
    times = []
    
    for i, cve_id in enumerate(test_cves, 1):
        print(f"  [{i}/{num_samples}] Collecting {cve_id}...", end=' ', flush=True)
        
        call_start = time.time()
        try:
            result = collector._collect_batch([cve_id])
            elapsed = time.time() - call_start
            times.append(elapsed)
            print(f"[OK] {elapsed:.2f}ì´ˆ")
        except Exception as e:
            elapsed = time.time() - call_start
            print(f"[ERROR] {elapsed:.2f}ì´ˆ - {str(e)[:50]}")
    
    total_time = time.time() - start
    
    if not times:
        return {
            'success': False,
            'error': 'All samples failed',
        }
    
    avg_time = sum(times) / len(times)
    effective_rate = 1.0 / avg_time if avg_time > 0 else 0
    
    return {
        'success': True,
        'samples': len(times),
        'times': {
            'total': total_time,
            'average': avg_time,
        },
        'effective_rate_per_hour': effective_rate * 3600,
        'recommendation': 'EPSS APIëŠ” ê³µê°œ APIì…ë‹ˆë‹¤. Rate limitì´ ì—†ìŠµë‹ˆë‹¤.',
    }


def _get_cve_recommendation(has_key: bool, avg_time: float, rate_limit: float) -> Dict[str, Any]:
    """Get detailed recommendation for CVE collection."""
    recommendations = []
    issues = []
    
    if not has_key:
        speedup = rate_limit / 0.6  # 6ì´ˆ â†’ 0.6ì´ˆ
        issues.append({
            'severity': 'high',
            'issue': 'NVD API í‚¤ ì—†ìŒ',
            'current_speed': f'{rate_limit:.1f}ì´ˆ/ìš”ì²­',
            'improved_speed': '0.6ì´ˆ/ìš”ì²­',
            'speedup': f'{speedup:.0f}ë°°',
            'action': 'NVD API í‚¤ ì„¤ì • í•„ìš”',
            'url': 'https://nvd.nist.gov/developers/request-an-api-key',
            'env_var': 'NVD_API_KEY'
        })
        recommendations.append(f"âš ï¸  NVD API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì„¤ì •í•˜ë©´ {speedup:.0f}ë°° ë¹¨ë¼ì§‘ë‹ˆë‹¤ (6ì´ˆ â†’ 0.6ì´ˆ).")
    else:
        recommendations.append("âœ… NVD API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    
    if avg_time > rate_limit * 1.5:
        issues.append({
            'severity': 'medium',
            'issue': 'ì‘ë‹µ ì‹œê°„ì´ ëŠë¦¼',
            'current_speed': f'{avg_time:.2f}ì´ˆ',
            'expected_speed': f'{rate_limit:.2f}ì´ˆ',
            'action': 'ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸ í•„ìš”',
        })
        recommendations.append(f"âš ï¸  ì‘ë‹µ ì‹œê°„ì´ ëŠë¦½ë‹ˆë‹¤ ({avg_time:.2f}ì´ˆ). ë„¤íŠ¸ì›Œí¬ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    elif avg_time < rate_limit * 0.8:
        recommendations.append(f"âœ… ì‘ë‹µ ì‹œê°„ì´ ë¹ ë¦…ë‹ˆë‹¤ ({avg_time:.2f}ì´ˆ). Rate limit ì—¬ìœ ê°€ ìˆìŠµë‹ˆë‹¤.")
    else:
        recommendations.append(f"â„¹ï¸  ì‘ë‹µ ì‹œê°„: {avg_time:.2f}ì´ˆ (ì •ìƒ ë²”ìœ„)")
    
    return {
        'summary': ' | '.join(recommendations),
        'issues': issues,
        'needs_api_key': not has_key,
    }


def _get_github_recommendation(remaining: Optional[int], limit: Optional[int], rate_per_hour: float) -> Dict[str, Any]:
    """Get detailed recommendation for GitHub collection."""
    recommendations = []
    issues = []
    
    if limit == 60:
        speedup = 5000 / 60  # 83ë°°
        issues.append({
            'severity': 'critical',
            'issue': 'GitHub API ë¹„ì¸ì¦ ìƒíƒœ',
            'current_limit': '60/hour',
            'improved_limit': '5000/hour',
            'speedup': f'{speedup:.0f}ë°°',
            'action': 'GitHub Personal Access Token ì„¤ì • í•„ìš”',
            'url': 'https://github.com/settings/tokens',
            'env_var': 'GITHUB_TOKEN',
            'impact': 'í˜„ì¬ ì†ë„ë¡œëŠ” ëŒ€ê·œëª¨ ìˆ˜ì§‘ ë¶ˆê°€ëŠ¥'
        })
        recommendations.append(f"âš ï¸  GitHub APIê°€ ë¹„ì¸ì¦ ìƒíƒœì…ë‹ˆë‹¤. GITHUB_TOKEN ì„¤ì • ì‹œ {speedup:.0f}ë°° ë¹¨ë¼ì§‘ë‹ˆë‹¤ (60 â†’ 5000/hour).")
    elif limit == 5000:
        recommendations.append("âœ… GitHub APIê°€ ì¸ì¦ ìƒíƒœì…ë‹ˆë‹¤.")
    
    if remaining is None or limit is None:
        recommendations.append("â„¹ï¸  Rate limit ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return {
            'summary': ' | '.join(recommendations),
            'issues': issues,
            'needs_token': limit == 60 if limit else None,
        }
    
    usage_percent = (limit - remaining) / limit * 100
    
    if usage_percent > 80:
        issues.append({
            'severity': 'high',
            'issue': 'Rate limit ì‚¬ìš©ë¥  ë†’ìŒ',
            'usage': f'{usage_percent:.1f}%',
            'remaining': remaining,
            'action': 'Rate limit ë³µêµ¬ ëŒ€ê¸° í•„ìš”',
        })
        recommendations.append(f"âš ï¸  Rate limit ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤ ({usage_percent:.1f}%). ì ì‹œ ëŒ€ê¸°í•˜ì„¸ìš”.")
    elif rate_per_hour > limit * 0.9:
        issues.append({
            'severity': 'medium',
            'issue': 'ìˆ˜ì§‘ ì†ë„ê°€ Rate limit ê·¼ì ‘',
            'current_rate': f'{rate_per_hour:.0f}/hour',
            'limit': f'{limit}/hour',
            'action': 'ìˆ˜ì§‘ ì†ë„ ì¡°ì ˆ í•„ìš”',
        })
        recommendations.append(f"âš ï¸  ìˆ˜ì§‘ ì†ë„ê°€ Rate limitì— ê·¼ì ‘í•©ë‹ˆë‹¤ ({rate_per_hour:.0f}/hour). ì†ë„ë¥¼ ì¤„ì´ì„¸ìš”.")
    else:
        recommendations.append(f"âœ… Rate limit ì—¬ìœ : {remaining}/{limit} ({100-usage_percent:.1f}% ë‚¨ìŒ)")
    
    return {
        'summary': ' | '.join(recommendations),
        'issues': issues,
        'needs_token': limit == 60,
        'rate_limit_usage': usage_percent,
    }


def estimate_collection_time(target_counts: Dict[str, int], results: Dict[str, Any]) -> Dict[str, Any]:
    """Estimate time needed for full collection."""
    estimates = {}
    
    # CVE estimates
    if 'cve' in results and results['cve'].get('success'):
        cve_result = results['cve']
        rate_per_hour = cve_result.get('effective_rate_per_hour', 0)
        if rate_per_hour > 0 and 'cve' in target_counts:
            hours = target_counts['cve'] / rate_per_hour
            estimates['cve'] = {
                'target_count': target_counts['cve'],
                'rate_per_hour': rate_per_hour,
                'estimated_hours': hours,
                'estimated_days': hours / 24,
            }
    
    # GitHub estimates
    if 'github' in results and results['github'].get('success'):
        github_result = results['github']
        rate_per_hour = github_result.get('commits_per_hour', 0)
        if rate_per_hour > 0 and 'commits' in target_counts:
            hours = target_counts['commits'] / rate_per_hour
            estimates['github'] = {
                'target_count': target_counts['commits'],
                'rate_per_hour': rate_per_hour,
                'estimated_hours': hours,
                'estimated_days': hours / 24,
            }
    
    return estimates


def analyze_bottlenecks(results: Dict[str, Any]) -> Dict[str, Any]:
    """Analyze bottlenecks and missing credentials."""
    bottlenecks = {
        'critical_issues': [],
        'high_priority': [],
        'recommendations': [],
        'estimated_impact': {},
    }
    
    # Check CVE API
    if 'cve' in results:
        cve_result = results['cve']
        if cve_result.get('success'):
            rec_details = cve_result.get('recommendation_details', {})
            if rec_details.get('needs_api_key'):
                bottlenecks['critical_issues'].append({
                    'api': 'NVD',
                    'issue': 'API í‚¤ ì—†ìŒ',
                    'current_rate': f"{cve_result.get('effective_rate_per_hour', 0):.0f}/hour",
                    'improved_rate': '6000/hour',
                    'speedup': '10ë°°',
                    'action': 'NVD_API_KEY í™˜ê²½ë³€ìˆ˜ ì„¤ì •',
                })
    
    # Check GitHub API
    if 'github' in results:
        github_result = results['github']
        if github_result.get('success'):
            rec_details = github_result.get('recommendation_details', {})
            if rec_details.get('needs_token'):
                bottlenecks['critical_issues'].append({
                    'api': 'GitHub',
                    'issue': 'ì¸ì¦ í† í° ì—†ìŒ',
                    'current_rate': f"{github_result.get('commits_per_hour', 0):.0f}/hour",
                    'improved_rate': '5000/hour',
                    'speedup': '83ë°°',
                    'action': 'GITHUB_TOKEN í™˜ê²½ë³€ìˆ˜ ì„¤ì •',
                })
        elif not github_result.get('success'):
            bottlenecks['critical_issues'].append({
                'api': 'GitHub',
                'issue': 'API í˜¸ì¶œ ì‹¤íŒ¨',
                'error': github_result.get('error', 'Unknown'),
                'action': 'GITHUB_TOKEN í™•ì¸ í•„ìš”',
            })
    
    # Estimate impact
    if bottlenecks['critical_issues']:
        bottlenecks['estimated_impact'] = {
            'message': 'ì¸ì¦ ì„¤ì • ì—†ì´ëŠ” ëŒ€ê·œëª¨ ë°ì´í„° ìˆ˜ì§‘ì´ ì–´ë µìŠµë‹ˆë‹¤.',
            'collection_time_multiplier': '10-83ë°°',
        }
    
    return bottlenecks


def generate_report(results: Dict[str, Any], estimates: Dict[str, Any]) -> str:
    """Generate collection speed report."""
    report = []
    report.append("=" * 80)
    report.append("Data Collection Speed Analysis")
    report.append("=" * 80)
    report.append(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append("")
    
    # Analyze bottlenecks
    bottlenecks = analyze_bottlenecks(results)
    
    # Summary
    report.append("## Summary")
    report.append("")
    
    for api_name, result in results.items():
        if result.get('success'):
            if api_name == 'cve':
                rate = result.get('effective_rate_per_hour', 0)
                auth = "ì¸ì¦" if result.get('authenticated') else "ë¹„ì¸ì¦"
                report.append(f"âœ… CVE: {rate:.0f}/hour ({auth})")
            elif api_name == 'github':
                rate = result.get('commits_per_hour', 0)
                auth = "ì¸ì¦" if result.get('authenticated') else "ë¹„ì¸ì¦"
                report.append(f"âœ… GitHub: {rate:.0f} commits/hour ({auth})")
            elif api_name == 'epss':
                rate = result.get('effective_rate_per_hour', 0)
                report.append(f"âœ… EPSS: {rate:.0f}/hour")
        else:
            report.append(f"âŒ {api_name.upper()}: {result.get('error', 'Unknown error')}")
    
    report.append("")
    
    # Critical Issues
    if bottlenecks['critical_issues']:
        report.append("## âš ï¸  Critical Issues (ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš”)")
        report.append("")
        for issue in bottlenecks['critical_issues']:
            report.append(f"### {issue['api']} API")
            report.append(f"- ë¬¸ì œ: {issue['issue']}")
            if 'current_rate' in issue:
                report.append(f"- í˜„ì¬ ì†ë„: {issue['current_rate']}")
                report.append(f"- ê°œì„  í›„: {issue['improved_rate']} ({issue['speedup']} ì¦ê°€)")
            if 'error' in issue:
                report.append(f"- ì˜¤ë¥˜: {issue['error']}")
            report.append(f"- ì¡°ì¹˜: {issue['action']}")
            report.append("")
    
    report.append("")
    
    # Detailed results
    report.append("## Detailed Results")
    report.append("")
    
    if 'cve' in results:
        cve = results['cve']
        report.append("### CVE Collection")
        report.append("")
        if cve.get('success'):
            times = cve.get('times', {})
            report.append(f"- Samples: {cve.get('samples', 0)}")
            report.append(f"- Average time: {times.get('average', 0):.2f}ì´ˆ")
            report.append(f"- Rate limit: {cve.get('rate_limit_seconds', 0)}ì´ˆ/ìš”ì²­")
            report.append(f"- Effective rate: {cve.get('effective_rate_per_hour', 0):.0f}/hour")
            report.append(f"- Bottleneck: {cve.get('bottleneck', 'unknown')}")
            report.append(f"- Recommendation: {cve.get('recommendation', 'N/A')}")
        else:
            report.append(f"- Error: {cve.get('error', 'Unknown')}")
        report.append("")
    
    if 'github' in results:
        github = results['github']
        report.append("### GitHub Collection")
        report.append("")
        if github.get('success'):
            report.append(f"- Commits collected: {github.get('commits_collected', 0)}")
            report.append(f"- Time: {github.get('time_seconds', 0):.2f}ì´ˆ")
            report.append(f"- Rate: {github.get('commits_per_hour', 0):.0f} commits/hour")
            if 'rate_limit' in github:
                rl = github['rate_limit']
                if rl.get('remaining') is not None:
                    report.append(f"- Rate limit: {rl.get('remaining')}/{rl.get('limit')} ë‚¨ìŒ")
            report.append(f"- Recommendation: {github.get('recommendation', 'N/A')}")
        else:
            report.append(f"- Error: {github.get('error', 'Unknown')}")
        report.append("")
    
    # Estimates
    if estimates:
        report.append("## Collection Time Estimates")
        report.append("")
        
        if 'cve' in estimates:
            est = estimates['cve']
            report.append(f"### CVE: {est['target_count']}ê°œ ìˆ˜ì§‘")
            report.append(f"- Rate: {est['rate_per_hour']:.0f}/hour")
            report.append(f"- Estimated time: {est['estimated_hours']:.2f}ì‹œê°„ ({est['estimated_days']:.2f}ì¼)")
            report.append("")
        
        if 'github' in estimates:
            est = estimates['github']
            report.append(f"### GitHub: {est['target_count']}ê°œ Commit ìˆ˜ì§‘")
            report.append(f"- Rate: {est['rate_per_hour']:.0f}/hour")
            report.append(f"- Estimated time: {est['estimated_hours']:.2f}ì‹œê°„ ({est['estimated_days']:.2f}ì¼)")
            report.append("")
    
    # Detailed Recommendations
    report.append("## Detailed Recommendations")
    report.append("")
    
    for api_name, result in results.items():
        if not result.get('success'):
            continue
            
        rec_details = result.get('recommendation_details', {})
        if not rec_details:
            continue
            
        report.append(f"### {api_name.upper()} API")
        report.append("")
        report.append(f"**ìš”ì•½**: {rec_details.get('summary', 'N/A')}")
        report.append("")
        
        issues = rec_details.get('issues', [])
        if issues:
            report.append("**ë°œê²¬ëœ ë¬¸ì œ:**")
            report.append("")
            for issue in issues:
                severity_icon = {'critical': 'ğŸ”´', 'high': 'ğŸŸ ', 'medium': 'ğŸŸ¡'}.get(issue.get('severity', ''), 'âšª')
                report.append(f"{severity_icon} **{issue.get('issue', 'Unknown')}**")
                if 'current_speed' in issue:
                    report.append(f"   - í˜„ì¬: {issue['current_speed']}")
                if 'improved_speed' in issue:
                    report.append(f"   - ê°œì„  í›„: {issue['improved_speed']}")
                if 'speedup' in issue:
                    report.append(f"   - ì†ë„ ì¦ê°€: {issue['speedup']}")
                if 'action' in issue:
                    report.append(f"   - ì¡°ì¹˜: {issue['action']}")
                if 'url' in issue:
                    report.append(f"   - ë§í¬: {issue['url']}")
                if 'env_var' in issue:
                    report.append(f"   - í™˜ê²½ë³€ìˆ˜: `export {issue['env_var']}=your_key`")
                report.append("")
        
        report.append("")
    
    # Overall Assessment
    report.append("## Overall Assessment")
    report.append("")
    
    all_authenticated = all(
        results.get(api, {}).get('authenticated', False) 
        for api in ['cve', 'github'] 
        if api in results and results[api].get('success')
    )
    
    if all_authenticated:
        report.append("âœ… **ëª¨ë“  APIê°€ ìµœì  ì„¤ì •ìœ¼ë¡œ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤.**")
        report.append("")
        report.append("ëŒ€ê·œëª¨ ë°ì´í„° ìˆ˜ì§‘ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
    else:
        report.append("âš ï¸  **ì¸ì¦ ì„¤ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.**")
        report.append("")
        report.append("í˜„ì¬ ì„¤ì •ìœ¼ë¡œëŠ”:")
        report.append("- ì†Œê·œëª¨ ë°ì´í„° ìˆ˜ì§‘ë§Œ ê°€ëŠ¥")
        report.append("- ìˆ˜ì§‘ ì‹œê°„ì´ ë§¤ìš° ì˜¤ë˜ ê±¸ë¦¼")
        report.append("- Rate limitì— ìì£¼ ê±¸ë¦¼")
        report.append("")
        report.append("**ê¶Œì¥ ì¡°ì¹˜:**")
        for issue in bottlenecks['critical_issues']:
            report.append(f"1. {issue['action']}")
        report.append("")
    
    return "\n".join(report)


def main():
    """Main entry point."""
    import argparse
    import requests
    
    parser = argparse.ArgumentParser(
        description="Measure actual data collection speed"
    )
    parser.add_argument(
        '--samples',
        type=int,
        default=5,
        help='Number of samples to test'
    )
    parser.add_argument(
        '--output',
        type=Path,
        default=Path('data/output/collection_speed_report.txt'),
        help='Output file for report'
    )
    
    args = parser.parse_args()
    
    print("Data Collection Speed Measurement")
    print("=" * 80)
    
    results = {}
    
    # Measure CVE collection
    try:
        results['cve'] = measure_cve_collection_speed(num_samples=args.samples)
    except Exception as e:
        results['cve'] = {'success': False, 'error': str(e)}
    
    # Measure GitHub collection
    try:
        results['github'] = measure_github_collection_speed()
    except Exception as e:
        results['github'] = {'success': False, 'error': str(e)}
    
    # Measure EPSS collection
    try:
        results['epss'] = measure_epss_collection_speed(num_samples=args.samples)
    except Exception as e:
        results['epss'] = {'success': False, 'error': str(e)}
    
    # Estimate collection time
    target_counts = {
        'cve': 100,  # 100 CVEs
        'commits': 1000,  # 1000 commits
    }
    estimates = estimate_collection_time(target_counts, results)
    
    # Generate report
    report = generate_report(results, estimates)
    
    # Print to console
    print("\n" + report)
    
    # Save to file
    args.output.parent.mkdir(parents=True, exist_ok=True)
    with open(args.output, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nğŸ“„ Report saved to: {args.output}")


if __name__ == '__main__':
    main()

